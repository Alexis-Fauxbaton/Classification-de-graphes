{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "#import pandas as pd\n",
    "#import re\n",
    "import itertools\n",
    "#from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code permettant de déterminer le score de similarité entre deux modèles à bloc stochastique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permut(pi):\n",
    "    a = len(pi)\n",
    "    b = np.math.factorial(a)\n",
    "    l = list(itertools.permutations(pi,a))\n",
    "    l_per = np.zeros((b,a))\n",
    "    k = 0\n",
    "    for i in l:\n",
    "        i = np.array(i)\n",
    "        l_per[k] = i\n",
    "        k = k+1\n",
    "    return l_per\n",
    "\n",
    "def cop(i,j,gamma,gamma2):\n",
    "    for k in range(len(gamma[0])):\n",
    "        gamma[j][k] = gamma2[i][k].copy()\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def inv_per(teta,pi_perm):\n",
    "    a = len(pi_perm)\n",
    "    gamma = teta[1]\n",
    "    gamma_inv = np.zeros((a,a))\n",
    "    for i in range (a):\n",
    "        for j in range (a):\n",
    "            if (teta[0][i] == pi_perm[j]):\n",
    "                for k in range(a):\n",
    "                    gamma_inv[k][j] = gamma[k][i]\n",
    "    gamma_inv2 = gamma_inv.copy()\n",
    "    for i in range (a):\n",
    "        for j in range (a):\n",
    "            if (teta[0][i] == pi_perm[j]):\n",
    "                gamma_inv = cop(i,j,gamma_inv,gamma_inv2)\n",
    "            #j = 0\n",
    "            #while((teta[0][i] != pi_perm[j]) & (j < a-1)):\n",
    "                #j = j+1\n",
    "            #gamma_inv = inv_l(i,j,gamma_inv,gamma_inv2)\n",
    "        \n",
    "    teta_inv = [pi_perm,gamma_inv]\n",
    "    return teta_inv\n",
    "\n",
    "\n",
    "def Calcul_sim(teta1,teta2):\n",
    "    pi1 = teta1[0]\n",
    "    gamma1 = teta1[1]\n",
    "    teta_2 = teta2\n",
    "    pi2 = teta_2[0]\n",
    "    gamma2 = teta_2[1]\n",
    "    err_pi = 0\n",
    "    err_gamma = 0\n",
    "    a = len(pi1)\n",
    "    for i in range(a):\n",
    "        if(pi1[i] != 0):\n",
    "            err_pi += 0.5*np.abs((pi1[i] - pi2[i])/pi1[i])\n",
    "        if(pi2[i] != 0):\n",
    "            err_pi += 0.5*np.abs((pi1[i] - pi2[i])/pi2[i])\n",
    "        for j in range(a):\n",
    "            if (gamma1[i][j] != 0):\n",
    "                err_gamma += 0.5*np.abs((gamma1[i][j] - gamma2[i][j])/gamma1[i][j])\n",
    "            if (gamma2[i][j] != 0):\n",
    "                err_gamma += 0.5*np.abs((gamma1[i][j] - gamma2[i][j])/gamma2[i][j])\n",
    "    sim = np.exp(-(err_pi + err_gamma))\n",
    "    return sim\n",
    "\n",
    "def Meilleur_sim(tet1,tet2):\n",
    "    sim = Calcul_sim(tet1,tet2)\n",
    "    a = len(tet1[0])\n",
    "    i = 0\n",
    "    k = np.math.factorial(a)\n",
    "    pi1_Q = np.arange(a)\n",
    "    pi1_M = tet1[0].copy()\n",
    "    pi2_Q = conv_r_Q(tet2[0],pi1_M,pi1_Q)\n",
    "    gamma1_Q = tet1[1].copy()\n",
    "    gamma2_Q = tet2[1].copy()\n",
    "    teta1 = [pi1_Q,gamma1_Q]\n",
    "    teta2 = [pi2_Q,gamma2_Q]\n",
    "    l_permut = np.zeros((k,a))\n",
    "    l_permut = permut(pi2_Q)\n",
    "    while(i != np.math.factorial(a)):\n",
    "        teta2_inv = inv_per(teta2,l_permut[i])\n",
    "        sim_inv = Calcul_sim(teta1,teta2_inv)\n",
    "        if (sim_inv > sim):\n",
    "            sim = sim_inv\n",
    "        i = i + 1\n",
    "    if (sim > sim_inv):\n",
    "        return sim\n",
    "    return sim_inv\n",
    "\n",
    "def conv_r_Q(pi_r,piM,piQ):\n",
    "    pi = pi_r.copy()\n",
    "    for i in range (len(piQ)):\n",
    "        for j in range (len(piQ)):\n",
    "            if (pi[i] == piM[j])&((piQ[j] in pi)==False):\n",
    "                pi[i] = piQ[j]\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Générant une matrice d'adjacence selon un modèle à bloc stochastique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "def SBM(Pi, Gamma, Q, n):\n",
    "    Adjacence = np.zeros((n,n))\n",
    "    classes = np.arange(1,Q+1)\n",
    "    classes_noeuds = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):#On initialise les classes de tous les noeuds\n",
    "        val = np.random.randint(1000)/1000\n",
    "        n_class = random.choices(classes, weights = Pi, k=1)[0]\n",
    "        classes_noeuds[i] = n_class\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                val = np.random.randint(1000)/1000\n",
    "                if val<=Gamma[int(classes_noeuds[i]-1)][int(classes_noeuds[j]-1)] :\n",
    "                    Adjacence[i,j] = 1\n",
    "                else:\n",
    "                    Adjacence[i,j] = 0\n",
    "            else:\n",
    "                Adjacence[i,j] = 0\n",
    "    return Adjacence, classes_noeuds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation de l'algorithme + Algorithme VEM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(M,Q):\n",
    "    kmeans = KMeans(n_clusters=Q).fit_predict(M)\n",
    "    Tau = np.zeros((M.shape[0],Q))\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(Q):\n",
    "            if kmeans[i] == j:\n",
    "                Tau[i,j] = 1\n",
    "            else:\n",
    "                Tau[i,j] = 0\n",
    "    return Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VEM(M,Q,T):\n",
    "    #Initialisation\n",
    "    Tau = init(M,Q)\n",
    "    Pi = np.zeros(Q)\n",
    "    Gamma = np.zeros((Q,Q))\n",
    "    n = M.shape[0]\n",
    "    #Étape A\n",
    "    for i in range(T):\n",
    "        for q in range(Q):\n",
    "            Pi[q] = 1/n * sum(Tau[:,q])\n",
    "        for q in range(Q):\n",
    "            for l in range(Q):\n",
    "                Gamma[q,l] = inner_sum(Tau,M,q,l)\n",
    "    #Étape B\n",
    "    for k in range(10):\n",
    "        for i in range(n):\n",
    "            for q in range(Q):\n",
    "                Tau[i,q] = inner_prod(Gamma,Pi,Tau,M,Q,q,i)\n",
    "            somme = sum(Tau[i,:])\n",
    "            for q in range(Q):\n",
    "                if somme != 0:\n",
    "                    Tau[i,q] = Tau[i,q]/somme\n",
    "                else:\n",
    "                    Tau[i,q] = 0\n",
    "    return Pi,Gamma,Tau\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "def inner_sum(Tau,M,q,l):\n",
    "    Num = 0\n",
    "    Den = 0\n",
    "    for i in range(Tau.shape[0]):\n",
    "        for j in range(Tau.shape[0]):\n",
    "            if i!=j:\n",
    "                Num+=Tau[i,q]*Tau[j,l]*M[i,j]\n",
    "                Den+=Tau[i,q]*Tau[j,l]\n",
    "    if Den == 0:\n",
    "        return 0\n",
    "    return Num/Den\n",
    "\n",
    "def inner_prod(Gamma,Pi,Tau,M,Q,q,i):\n",
    "    prod = 1\n",
    "    for j in range(M.shape[0]):\n",
    "        for l in range(Q):\n",
    "            prod *= pow(pow(Gamma[q,l],M[i,j])*pow(1-Gamma[q,l],1-M[i,j]),Tau[j,l])\n",
    "    return Pi[q]*prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critère ICL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL = 1e-10\n",
    "def ICL(M,Q,n):\n",
    "    Pi,Gamma,Tau = VEM(M,Q,100)\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    for i in range(n):\n",
    "        for q in range(Q):\n",
    "            #print(i,q)\n",
    "            sum1 += Tau[i,q]*np.log(Pi[q])\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                for q in range(Q):\n",
    "                    for l in range(Q):\n",
    "                        #print(i,j,q,l)\n",
    "                        mul = Tau[i,q]*Tau[j,l]\n",
    "                        #print(\"mul :\",mul)\n",
    "                        #print(\"M[i,j] :\",M[i,j])\n",
    "                        #print(mul*(M[i,j]*np.log(Gamma[q,l]) + (1-M[i,j])*np.log(1-Gamma[q,l])))\n",
    "                        #sum2 += mul*(M[i,j]*np.log(Gamma[q,l]) + (1-M[i,j])*np.log(1-Gamma[q,l]))\n",
    "                        sum2 += mul*(M[i,j]*np.log(Gamma[q,l] + SMALL) + (1-M[i,j])*np.log(1-Gamma[q,l] + SMALL))\n",
    "    A = sum1 + sum2\n",
    "    icl = A - 0.5*(Q-1)*np.log(n) - 0.5*Q*(Q+1)*0.5*np.log(n*(n-1)/2)\n",
    "    return icl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la suite de toutes les matrices d'adjacence des graphes du Dataset Tox_21_ARE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_index(n,Lines,graph,start):\n",
    "    count = -1\n",
    "    for i in range(start,len(Lines)):\n",
    "        #print(int(Lines[i]),graph)\n",
    "        if int(Lines[i]) == graph:\n",
    "            count+=1\n",
    "            #print(i+1,Lines[i],count)\n",
    "        if i+1 == n:\n",
    "            return count\n",
    "\n",
    "def create_df(filename1,filename2,filename3,matrix_len):\n",
    "    file1 = open(filename1,'r')#liaisons\n",
    "    file2 = open(filename2,'r')#quel graphe\n",
    "    file3 = open(filename3,'r')#quelle classe\n",
    "    Lines1 = file1.readlines()\n",
    "    Lines2 = file2.readlines()\n",
    "    Lines3 = file3.readlines()\n",
    "    matrixes = [0 for i in range(matrix_len)]\n",
    "    start = [0 for i in range(matrix_len)]\n",
    "    sizes = np.zeros(matrix_len)\n",
    "    classes = []\n",
    "    count = -1\n",
    "    count2 = 0\n",
    "    val = 0\n",
    "    length = 0\n",
    "    #print(len(Lines2))\n",
    "    for i in range(len(Lines2)):\n",
    "        if int(Lines2[i]) != val:\n",
    "            val = int(Lines2[i])\n",
    "            start[count2] = i\n",
    "            count2+=1\n",
    "            sizes[count]+=1\n",
    "            count+=1\n",
    "        else:\n",
    "            sizes[count]+=1\n",
    "    \n",
    "    for i in range(len(sizes)):\n",
    "        matrixes[i] = np.zeros((int(sizes[i]),int(sizes[i])))\n",
    "    \n",
    "    for i in range(len(Lines3)):\n",
    "        classes.append(int(Lines3[i]))\n",
    "    \n",
    "    compteur = 0\n",
    "    for line in Lines1:\n",
    "        #print(compteur)\n",
    "        n1 = \"\"\n",
    "        n2 = \"\"\n",
    "        #print(line[0])\n",
    "        i = 0\n",
    "        while(line[i] != ','):\n",
    "            n1+=line[i]\n",
    "            i+=1\n",
    "        i = i+1\n",
    "        while(line[i]!='\\n'):\n",
    "            n2+=line[i]\n",
    "            i+=1\n",
    "        n1 = int(n1)\n",
    "        n2 = int(n2)\n",
    "        i = int(Lines2[n1-1])-1\n",
    "        #print(n1,start[i])\n",
    "        index1 = get_index(n1,Lines2,i+1,start[i])\n",
    "        index2 = get_index(n2,Lines2,i+1,start[i])\n",
    "        matrixes[i][index1,index2] = 1\n",
    "        compteur+=1\n",
    "        \n",
    "    return matrixes,classes,sizes\n",
    "\n",
    "matrixes,classes,sizes = create_df(\"Tox21_ARE_evaluation/Tox21_ARE_evaluation_A.txt\",\"Tox21_ARE_evaluation/Tox21_ARE_evaluation_graph_indicator.txt\",\"Tox21_ARE_evaluation/Tox21_ARE_evaluation_graph_labels.txt\",552)        \n",
    "matrixesT,classesT,sizesT = create_df(\"Tox21_ARE_testing/Tox21_ARE_testing_A.txt\",\"Tox21_ARE_testing/Tox21_ARE_testing_graph_indicator.txt\",\"Tox21_ARE_testing/Tox21_ARE_testing_graph_labels.txt\",234)\n",
    "matrixesG,classesG,sizesG = create_df(\"Tox21_ARE_training/Tox21_ARE_training_A.txt\",\"Tox21_ARE_training/Tox21_ARE_training_graph_indicator.txt\",\"Tox21_ARE_training/Tox21_ARE_training_graph_labels.txt\",7167)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détermination du nombre optimal de classes pour l'ensemble de graphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On teste le critère ICL sur 10 graphes différents pris à des endroits différents du Dataset pour un nombre de classes de noeuds variant entre 2 et 5 puis on garde le nombre optimal de classes du Dataset comme étant la médiane du nombre optimal de classes pour chacun des graphes testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = 10\n",
    "elements = np.zeros(sample)\n",
    "\n",
    "for i in range(sample):\n",
    "    #print(i)\n",
    "    N = np.arange(2,6)\n",
    "    #print(N)\n",
    "    icls = [ICL(matrixes[i*13],k,matrixes[i*13].shape[0]) for k in range(2, 6)]\n",
    "    #print(icls)\n",
    "    #plt.plot(N,np.array(icls))\n",
    "    #plt.show()\n",
    "    index, value = max(enumerate(icls), key=operator.itemgetter(1))\n",
    "    elements[i] = index+2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elements)\n",
    "\n",
    "Q = int(np.median(elements))\n",
    "print(\"Le nombre optimal de classes retenu est de \",Q)\n",
    "Q = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour éviter les cas où un graphe possède moins de sommets que de nombre de classes de noeuds différentes dans son modèle à bloc stochastique, on retire du jeu de données d'entraînement les graphes possédant cette caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes2 = []\n",
    "classes2 = []\n",
    "sizes2 = []\n",
    "indexes = []\n",
    "for i in range(len(matrixes)):\n",
    "    if matrixes[i].shape[0]>=Q:\n",
    "        matrixes2.append(matrixes[i])\n",
    "        classes2.append(classes[i])\n",
    "        sizes2.append(sizes[i])\n",
    "    else:\n",
    "        indexes.append(i)\n",
    "matrixes = matrixes2.copy()\n",
    "classes = classes2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On effectue la même opération sur le jeu de données de test de taille moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes2T = []\n",
    "classes2T = []\n",
    "sizes2T = []\n",
    "indexesT = []\n",
    "for i in range(len(matrixesT)):\n",
    "    if matrixesT[i].shape[0]>=Q:\n",
    "        matrixes2T.append(matrixes[i])\n",
    "        classes2T.append(classes[i])\n",
    "        sizes2T.append(sizes[i])\n",
    "    else:\n",
    "        indexesT.append(i)\n",
    "classesT = classes2T.copy()\n",
    "matrixesT = matrixes2T.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On effectue la même opération sur le jeu de données de test de grande taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes2G = []\n",
    "classes2G = []\n",
    "sizes2G = []\n",
    "indexesG = []\n",
    "for i in range(len(matrixesG)):\n",
    "    if matrixesG[i].shape[0]>=Q:\n",
    "        matrixes2G.append(matrixesG[i])\n",
    "        classes2G.append(classesG[i])\n",
    "        sizes2G.append(sizesG[i])\n",
    "    else:\n",
    "        indexesG.append(i)\n",
    "classesG = classes2G.copy()\n",
    "matrixesG = matrixes2G.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grâce à l'algorithme VEM, on va déterminer une approximation des paramètres du modèle à bloc stochastique pour chaque graphe du jeu de données d'entraînement dans une liste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Infos = [0 for i in range(len(matrixes))]\n",
    "for i in range(len(matrixes)):\n",
    "    #print(i)\n",
    "    Infos[i] = VEM(matrixes[i],Q,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On effectue le même procédé sur le jeu de données de test de taille moyenne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "InfosT = [0 for i in range(len(matrixesT))]\n",
    "for i in range(len(matrixesT)):\n",
    "    #print(i)\n",
    "    InfosT[i] = VEM(matrixesT[i],Q,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On effectue le même procédé sur le jeu de données d'entraînement de grande taille :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "InfosG = [0 for i in range(len(matrixesG))]\n",
    "for i in range(len(matrixesG)):\n",
    "    InfosG[i] = VEM(matrixesG[i],Q,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la matrice de similarité entre les graphes de l'échantillon d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = np.zeros((len(Infos),len(Infos)))\n",
    "len_train = len(Infos)\n",
    "for i in range(len_train):\n",
    "    for j in range(len_train):\n",
    "        X_train[i,j] = Meilleur_sim(Infos[i],Infos[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la matrice de similarité entre chaque graphes du jeu de données de test de taille moyenne et chaque graphe du jeu de données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len_test = len(matrixesT)\n",
    "X_T = np.zeros((len_test,len(Infos)))\n",
    "for i in range(len_test):\n",
    "    for j in range(len(Infos)):\n",
    "        X_T[i,j] = Meilleur_sim(InfosT[i],Infos[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la matrice de similarité entre chaque graphe du jeu de données de test de grande taille et chaque graphe du jeu de données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_G = np.zeros((len(InfosG),len(Infos)))\n",
    "len_G = len(InfosG)\n",
    "for i in range(len_G):\n",
    "    for j in range(len_train):\n",
    "        X_G[i,j] = Meilleur_sim(InfosG[i],Infos[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des différents graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation et entraînement de l'algorithme de machine learning sur le jeu de données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='precomputed')\n",
    "svc.fit(X_train,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions de l'algorithme entraîné sur les jeux de données de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svc.predict(X_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(classesT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Précision de l'algorithme sur le jeu de données de test de taille moyenne puis sur celui de grande taille :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.score(X_T,classesT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.score(X_G,classesG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "#dump(svc, 'svc_tox_precomputed_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
